# -*- coding: utf-8 -*-
"""Task3&4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17daIJoaGlRwxbZ1QsPfIqRN_6kV5IYdd
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import pickle
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from keras.models import Model
from tensorflow.keras import layers
from tensorflow.keras.optimizers import Adam, SGD, Adagrad, RMSprop
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard

"""#### Dataset"""

with open('/content/drive/MyDrive/Deep_learning/Group_9_Assgnment3/x_train.pkl', 'rb') as f:
    x_train = pickle.load(f)
with open('/content/drive/MyDrive/Deep_learning/Group_9_Assgnment3/y_train.pkl', 'rb') as f:
    y_train = pickle.load(f)

with open('/content/drive/MyDrive/Deep_learning/Group_9_Assgnment3/x_test.pkl', 'rb') as f:
    x_test = pickle.load(f)
with open('/content/drive/MyDrive/Deep_learning/Group_9_Assgnment3/y_test.pkl', 'rb') as f:
    y_test = pickle.load(f)

with open('/content/drive/MyDrive/Deep_learning/Group_9_Assgnment3/x_val.pkl', 'rb') as f:
    x_val = pickle.load(f)
with open('/content/drive/MyDrive/Deep_learning/Group_9_Assgnment3/y_val.pkl', 'rb') as f:
    y_val = pickle.load(f)

def relabel(data):
  class_labels = np.array(data)
  label_map = {label: i for i, label in enumerate(np.unique(class_labels))}
  integer_labels = np.array([label_map[label] for label in class_labels])
  print(label_map)
  return integer_labels.tolist()

y_train=relabel(y_train)
y_test=relabel(y_test)
y_val=relabel(y_val)

x_train = np.array(x_train).reshape(-1, 784).tolist()
x_test = np.array(x_test).reshape(-1, 784).tolist()
x_val = np.array(x_val).reshape(-1, 784).tolist()

"""#### Encoder"""

autoencoder = keras.models.load_model('/content/drive/MyDrive/Deep_learning/Group_9_Assignment4/1-layer_Autoencoder/256_1-layer_Autoencoder_model.h5')

encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('Bottleneck_layer').output)
encoder.summary()

compressed_x_train= encoder.predict(x_train)
compressed_x_test= encoder.predict(x_test)
compressed_x_val= encoder.predict(x_val)

compressed_x_train=compressed_x_train.tolist()
compressed_x_test=compressed_x_test.tolist()
compressed_x_val=compressed_x_val.tolist()

"""#### FCNN Architecture"""

#num_classes = 10 
# num_features = 784
# learning_rate = 0.001

# # batch_size = 1
# # #display_step = 100
#model 1
n_hidden_1 = 128  
n_hidden_2 = 64  
n_hidden_3 = 32

# #model 2
# n_hidden_1 = 256  
# n_hidden_2 = 128  
# n_hidden_3 = 64

# #model 3
# n_hidden_1 = 512  
# n_hidden_2 = 256
# n_hidden_3 = 128

initializer = keras.initializers.RandomUniform(minval=-1, maxval=1, seed=100)
early_stopping = EarlyStopping(monitor='val_loss', patience=5, min_delta=0.0001)

bottleneck_size=64

model = keras.Sequential([
        layers.Input(shape=(bottleneck_size, ),name="Input_layer"),
        layers.Dense(n_hidden_1, activation="tanh", name="Hidden_layer1"),
        layers.Dense(n_hidden_2, activation="tanh", name="Hidden_layer2"),
        layers.Dense(n_hidden_3, activation="tanh", name="Hidden_layer3"),
        layers.Dense(5, activation="softmax", name="output"),
        ])
model.summary()

Adam_optimizer=Adam(learning_rate=0.001, beta_1=0.9,beta_2=0.999, epsilon=1e-08, name="Adam")

model.compile(optimizer=Adam_optimizer, loss= "sparse_categorical_crossentropy", metrics=['accuracy'])

history = model.fit(compressed_x_train, y_train, batch_size=1, epochs=500000, validation_data=(compressed_x_val, y_val), verbose=1, shuffle=True, callbacks=[early_stopping], validation_split=0.0, validation_batch_size=None)

with open(f"/content/drive/MyDrive/Deep_learning/Group_9_Assignment4/1-layer_encoder/"+str(bottleneck_size)+"components_"+str(n_hidden_1)+"_"+str(n_hidden_2)+"_"+str(n_hidden_3)+"_history.pkl", 'wb') as f:
    pickle.dump(history.history, f)

model.save(f"/content/drive/MyDrive/Deep_learning/Group_9_Assignment4/1-layer_encoder/"+str(bottleneck_size)+"components_"+str(n_hidden_1)+"_"+str(n_hidden_2)+"_"+str(n_hidden_3)+"_model.h5")

"""#### Results"""

with open('/content/drive/MyDrive/Deep_learning/Group_9_Assignment4/2-layer_encoder/32components_512_128_64_history.pkl', 'rb') as f:
    history = pickle.load(f)

print("Total No. of Epochs to converge "+ str(len(history['accuracy']))+"\n")
print("Training Accuracy "+ str(history['accuracy'][-1]))
print("Validation Accuracy "+ str(history['val_accuracy'][-1]))

model = keras.models.load_model('/content/drive/MyDrive/Deep_learning/Group_9_Assignment4/1-layer_encoder/256components_128_64_32_model.h5')
#model.reset_states()
predictions = model.predict(compressed_x_test)
conf_matrix=tf.math.confusion_matrix(y_test,predictions.argmax(axis=1))

accuracy = tf.metrics.Accuracy()(y_test, predictions.argmax(axis=1))

# Print the metrics
print("Confusion matrix:\n", conf_matrix.numpy())
print("Accuracy:", accuracy.numpy())