# -*- coding: utf-8 -*-
"""Group09_Assignment5_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/113D1x-pLdAvbsa6V6MJgjA0AdKn7_SuH
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import pickle
import cv2
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from keras.models import Model
from tensorflow.keras import layers
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

"""#### Dataset"""

def Dataset(path):
    data = []
    label= []
    for subdir, dirs, filenames in os.walk(path):
        for filename in filenames:
            image = cv2.imread(os.path.join(subdir, filename))
            image =image.astype("float32") / 255.0
            data.append(cv2.resize(image, (224, 224)))
            #data.append(img)
            label.append(subdir.split("/")[-1])
    return np.array(data), np.array(label)

train_directory="/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Group_9/train"
x_train,y_train=Dataset(train_directory)

val_directory="/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Group_9/val"
x_val,y_val=Dataset(val_directory)

test_directory="/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Group_9/test"
x_test,y_test=Dataset(test_directory)

with open(f"/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/x_train.pkl", 'wb') as f:
    pickle.dump(x_train, f)

with open(f"/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/y_train.pkl", 'wb') as f:
    pickle.dump(y_train, f)

with open(f"/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/x_test.pkl", 'wb') as f:
    pickle.dump(x_test, f)

with open(f"/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/y_test.pkl", 'wb') as f:
    pickle.dump(y_test, f)

with open(f"/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/x_val.pkl", 'wb') as f:
    pickle.dump(x_val, f)

with open(f"/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/y_val.pkl", 'wb') as f:
    pickle.dump(y_val, f)

"""#### Load Dataset"""

with open('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Dataset/x_train.pkl', 'rb') as f:
    x_train = pickle.load(f)
with open('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Dataset/y_train.pkl', 'rb') as f:
    y_train = pickle.load(f)

with open('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Dataset/x_test.pkl', 'rb') as f:
    x_test = pickle.load(f)
with open('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Dataset/y_test.pkl', 'rb') as f:
    y_test = pickle.load(f)

with open('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Dataset/x_val.pkl', 'rb') as f:
    x_val = pickle.load(f)
with open('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Dataset/y_val.pkl', 'rb') as f:
    y_val = pickle.load(f)

def relabel(class_labels):
  label_map = {label: i for i, label in enumerate(np.unique(class_labels))}
  integer_labels = np.array([label_map[label] for label in class_labels])
  print(label_map)
  return integer_labels

y_train=relabel(y_train)
y_test=relabel(y_test)
y_val=relabel(y_val)

"""## Task 1

#### Architecture 1
"""

early_stopping = EarlyStopping(monitor='val_loss', patience=5, min_delta=0.0001)

model = Sequential()
model.add(Conv2D(8, (11,11), strides=4, padding='valid',name="Convolution_Layer_1", activation='relu', input_shape=(224,224,3)))
model.add(MaxPooling2D(pool_size=(3,3),name="MaxPooling_Layer_1", strides=2))

model.add(Conv2D(16, (5,5), strides=1,name="Convolution_Layer_2" ,padding='valid', activation='relu'))
model.add(MaxPooling2D(pool_size=(3,3),name="MaxPooling_Layer_2", strides=2))

model.add(Flatten())
model.add(Dense(128,name="Classification_Layer_1", activation='relu'))
model.add(Dense(5,name="Classification_Layer_2", activation='softmax'))

model.summary()

Adam_optimizer=Adam(learning_rate=0.0001, beta_1=0.9,beta_2=0.999, epsilon=1e-08, name="Adam")

model.compile(optimizer='Adam', loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])

history = model.fit(x_train, y_train, batch_size=1, epochs=500000, validation_data=(x_val, y_val),verbose=1,shuffle=True,callbacks=[early_stopping], validation_split=0.0, validation_batch_size=None)

with open(f"/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/Architecure_1_history.pkl", 'wb') as f:
    pickle.dump(history.history, f)

model.save(f"/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/Architecure_1_model.h5")

with open('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/Architecure_1_history.pkl', 'rb') as f:
    history = pickle.load(f)

print("Total No. of Epochs to converge "+ str(len(history['accuracy']))+"\n")
print("Training Accuracy "+ str(history['accuracy'][-1]))
print("Validation Accuracy "+ str(history['val_accuracy'][-1]))

model = keras.models.load_model('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/Architecure_1_model.h5')

predictions = model.predict(x_test)
conf_matrix=tf.math.confusion_matrix(y_test,predictions.argmax(axis=1))

accuracy = tf.metrics.Accuracy()(y_test, predictions.argmax(axis=1))

print("Confusion matrix:\n", conf_matrix.numpy())
print("Accuracy:", accuracy.numpy())

"""#### Architecture 2"""

early_stopping = EarlyStopping(monitor='val_loss', patience=5, min_delta=0.0001)

pretrained_model = keras.models.load_model('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/Architecure_1_model.h5')

model = Sequential()

for layer in pretrained_model.layers:
    if layer.name == 'MaxPooling_Layer_2':
        break
    model.add(layer)
model.add(layer)

model.add(Conv2D(64, (3,3), strides=1, name="Convolution_Layer_3", padding='valid', activation='relu'))
model.add(MaxPooling2D(pool_size=(3,3), name="MaxPooling_Layer_3", strides=2))

model.add(Flatten())
model.add(Dense(128, name="Classification_Layer_1", activation='relu'))
model.add(Dense(5, name="Classification_Layer_2", activation='softmax'))

# Print model summary
model.summary()

# model = Sequential()

# model.add(Conv2D(8, (11,11), strides=4, padding='valid',name="Convolution_Layer_1", activation='relu', input_shape=(224,224,3)))
# model.add(MaxPooling2D(pool_size=(3,3),name="MaxPooling_Layer_1", strides=2))

# model.add(Conv2D(16, (5,5), strides=1,name="Convolution_Layer_2" ,padding='valid', activation='relu'))
# model.add(MaxPooling2D(pool_size=(3,3),name="MaxPooling_Layer_2", strides=2))

# model.add(Conv2D(32, (3,3), strides=1,name="Convolution_Layer_3" ,padding='valid', activation='relu'))
# model.add(MaxPooling2D(pool_size=(3,3),name="MaxPooling_Layer_3", strides=2))

# model.add(Flatten())
# model.add(Dense(128,name="Classification_Layer_1", activation='relu'))
# model.add(Dense(5,name="Classification_Layer_2", activation='softmax'))


# model.summary()

Adam_optimizer=Adam(learning_rate=0.001, beta_1=0.9,beta_2=0.999, epsilon=1e-08, name="Adam")

model.compile(optimizer=Adam_optimizer, loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])

history = model.fit(x_train, y_train, batch_size=1, epochs=500000, validation_data=(x_val, y_val),verbose=1,shuffle=True,callbacks=[early_stopping], validation_split=0.0, validation_batch_size=None)

with open(f"/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/Architecure_2_history.pkl", 'wb') as f:
    pickle.dump(history.history, f)

model.save(f"/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/Architecure_2_model.h5")

with open('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/Architecure_2_history.pkl', 'rb') as f:
    history = pickle.load(f)

print("Total No. of Epochs to converge "+ str(len(history['accuracy']))+"\n")
print("Training Accuracy "+ str(history['accuracy'][-1]))
print("Validation Accuracy "+ str(history['val_accuracy'][-1]))

model = keras.models.load_model('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/Architecure_2_model.h5')

predictions = model.predict(x_test)
conf_matrix=tf.math.confusion_matrix(y_test,predictions.argmax(axis=1))

accuracy = tf.metrics.Accuracy()(y_test, predictions.argmax(axis=1))

print("Confusion matrix:\n", conf_matrix.numpy())
print("Accuracy:", accuracy.numpy())

"""#### Architecture 3 """

early_stopping = EarlyStopping(monitor='val_loss', patience=5, min_delta=0.0001)

pretrained_model = keras.models.load_model('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/Architecure_2_model.h5')

model = Sequential()

for layer in pretrained_model.layers:
    if layer.name == 'Convolution_Layer_3':
        break
    model.add(layer)
model.add(layer)

#model.add(Conv2D(32, (3,3), strides=1, name="Convolution_Layer_3", padding='valid', activation='relu'))

model.add(Conv2D(64, (3,3), strides=1, name="Convolution_Layer_4", padding='valid', activation='relu'))
model.add(MaxPooling2D(pool_size=(3,3), name="MaxPooling_Layer_4", strides=2))

model.add(Flatten())
model.add(Dense(128, name="Classification_Layer_1", activation='relu'))
model.add(Dense(5, name="Classification_Layer_2", activation='softmax'))

# Print model summary
model.summary()

# model = Sequential()

# model.add(Conv2D(8, (11,11), strides=4, padding='valid',name="Convolution_Layer_1", activation='relu', input_shape=(224,224,3)))
# model.add(MaxPooling2D(pool_size=(3,3),name="MaxPooling_Layer_1", strides=2))

# model.add(Conv2D(16, (5,5), strides=1,name="Convolution_Layer_2" ,padding='valid', activation='relu'))
# model.add(MaxPooling2D(pool_size=(3,3),name="MaxPooling_Layer_2", strides=2))

# model.add(Conv2D(32, (3,3), strides=1,name="Convolution_Layer_3" ,padding='valid', activation='relu'))

# model.add(Conv2D(64, (3,3), strides=1,name="Convolution_Layer_4" ,padding='valid', activation='relu'))
# model.add(MaxPooling2D(pool_size=(3,3),name="MaxPooling_Layer_4", strides=2))

# model.add(Flatten())
# model.add(Dense(128,name="Classification_Layer_1", activation='relu'))
# model.add(Dense(5,name="Classification_Layer_2", activation='softmax'))


# model.summary()

Adam_optimizer=Adam(learning_rate=0.001, beta_1=0.9,beta_2=0.999, epsilon=1e-08, name="Adam")

model.compile(optimizer=Adam_optimizer, loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])

history = model.fit(x_train, y_train, batch_size=1, epochs=500000, validation_data=(x_val, y_val),verbose=1,shuffle=True,callbacks=[early_stopping], validation_split=0.0, validation_batch_size=None)

with open(f"/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/Architecure_3_history.pkl", 'wb') as f:
    pickle.dump(history.history, f)

model.save(f"/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/Architecure_3_model.h5")

with open('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/Architecure_3_history.pkl', 'rb') as f:
    history = pickle.load(f)

print("Total No. of Epochs to converge "+ str(len(history['accuracy']))+"\n")
print("Training Accuracy "+ str(history['accuracy'][-1]))
print("Validation Accuracy "+ str(history['val_accuracy'][-1]))

model = keras.models.load_model('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/Architecure_3_model.h5')

predictions = model.predict(x_test)
conf_matrix=tf.math.confusion_matrix(y_test,predictions.argmax(axis=1))

accuracy = tf.metrics.Accuracy()(y_test, predictions.argmax(axis=1))

print("Confusion matrix:\n", conf_matrix.numpy())
print("Accuracy:", accuracy.numpy())

"""#### Results"""

image = cv2.imread('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/chandelier.jpg')
image =image.astype("float32") / 255.0
img=cv2.resize(image, (224, 224))


model = keras.models.load_model('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/Architecure_1_model.h5')

layer_outputs = [layer.output for layer in model.layers if 'Convolution_Layer_1' in layer.name]
activation_model = Model(inputs=model.input, outputs=layer_outputs)
activations = activation_model.predict(np.expand_dims(img, axis=0))

plt.imshow(image, cmap='gray')

import matplotlib.pyplot as plt

fig, axs = plt.subplots(2, 4, figsize=(8,4))
for i in range(2):
    for j in range(4):
        axs[i,j].imshow(activations[0,:,:,i*4+j])
        axs[i,j].axis('off')
plt.show()

model = keras.models.load_model('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/Architecure_1_model.h5')

layer_outputs = [layer.output for layer in model.layers if 'Convolution_Layer_2' in layer.name]
activation_model = Model(inputs=model.input, outputs=layer_outputs)
activations = activation_model.predict(np.expand_dims(img, axis=0))

import matplotlib.pyplot as plt

fig, axs = plt.subplots(2, 8, figsize=(16,4))
for i in range(2):
    for j in range(8):
        axs[i,j].imshow(activations[0,:,:,i*8+j])
        axs[i,j].axis('off')
plt.show()

"""#### Visualising Patch"""

image = cv2.imread('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/chandelier.jpg')
image = cv2.resize(image, (224, 224))
plt.imshow(image, cmap='gray')

image.shape

model = keras.models.load_model('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/Architecure_1_model.h5')

layer_outputs = [layer.output for layer in model.layers if layer.name == 'Convolution_Layer_2']
activation_model = Model(inputs=model.input, outputs=layer_outputs)
test = np.expand_dims(image, axis=0)
print(test.shape)
     
last_conv=activation_model.predict(test)

for i in range(16):
  plt.subplot(4, 4, i+1)
  plt.imshow(np.squeeze(last_conv[:, :, :, i]))
  plt.axis('off')
plt.show()

max_pos = np.argmax(np.squeeze(last_conv[:, :, :, 1]))
max_pos

np.ndarray.flatten(np.squeeze(last_conv[:, :, :, i]))[max_pos], np.amax(np.squeeze(last_conv[:, :, :, 1]))

layer_outputs = [layer.output for layer in model.layers if layer.name == 'Convolution_Layer_2']
activation_model = Model(inputs=model.input, outputs=layer_outputs)
test = np.expand_dims(image, axis=0)
Convolution_Layer_2_Feature=activation_model.predict(test)

layer_outputs = [layer.output for layer in model.layers if layer.name == 'Convolution_Layer_1']
activation_model = Model(inputs=model.input, outputs=layer_outputs)
test = np.expand_dims(image, axis=0)
Convolution_Layer_1_Feature=activation_model.predict(test)

Convolution_Layer_2_Feature.shape

Convolution_Layer_1_Feature.shape

max_value = np.max(np.squeeze(last_conv[:, :, :, 1]))
max_pos = np.where(np.squeeze(last_conv[:, :, :, 1]) == max_value)
max_pos = (max_pos[0][0], max_pos[1][0])
max_pos

def trace_patch1(max_pos):
  '''
  This is for stride 1 and padding 1 and (3*3 filter size)
  Written in a most shit way, you can generalize it further.
  '''
  #order matters
  pos = [(max_pos[0]-1, max_pos[1]-1), (max_pos[0], max_pos[1]-1), (max_pos[0]+1, max_pos[1]-1),
              (max_pos[0]-1, max_pos[1]), (max_pos[0], max_pos[1]), (max_pos[0]+1, max_pos[1]), 
              (max_pos[0]-1, max_pos[1]+1), (max_pos[0], max_pos[1]+1), (max_pos[0]+1, max_pos[1]+1)]

  return pos

"""## Task 2"""

early_stopping = EarlyStopping(monitor='val_loss', patience=5, min_delta=0.0001)

from tensorflow.keras.applications.vgg19 import VGG19

base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

model = Sequential()

for layer in base_model.layers:
    layer.trainable = False
    model.add(layer)

model.add(Flatten())
model.add(Dense(5, name="Classification_Layer_1", activation='softmax'))

model.summary()

Adam_optimizer=Adam(learning_rate=0.001, beta_1=0.9,beta_2=0.999, epsilon=1e-08, name="Adam")

model.compile(optimizer=Adam_optimizer, loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])

history = model.fit(x_train, y_train, batch_size=1, epochs=10, validation_data=(x_val, y_val),verbose=1,shuffle=True,callbacks=[early_stopping], validation_split=0.0, validation_batch_size=None)

with open(f"/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/VGG19_history.pkl", 'wb') as f:
    pickle.dump(history.history, f)

model.save(f"/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/VGG19_model.h5")

with open('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/VGG19_history.pkl', 'rb') as f:
    history = pickle.load(f)

print("Total No. of Epochs to converge "+ str(len(history['accuracy']))+"\n")
print("Training Accuracy "+ str(history['accuracy'][-1]))
print("Validation Accuracy "+ str(history['val_accuracy'][-1]))

model = keras.models.load_model('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/VGG19_model.h5')

predictions = model.predict(x_test)
conf_matrix=tf.math.confusion_matrix(y_test,predictions.argmax(axis=1))

accuracy = tf.metrics.Accuracy()(y_test, predictions.argmax(axis=1))

print("Confusion matrix:\n", conf_matrix.numpy())
print("Test Accuracy:", accuracy.numpy())

"""#### Results"""

image = cv2.imread('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/chandelier.jpg')
image =image.astype("float32") / 255.0
img=cv2.resize(image, (224, 224))


model = keras.models.load_model('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/VGG19_model.h5')

layer_outputs = [layer.output for layer in model.layers if 'block1_conv1' in layer.name]
activation_model = Model(inputs=model.input, outputs=layer_outputs)
activations = activation_model.predict(np.expand_dims(img, axis=0))

import matplotlib.pyplot as plt

fig, axs = plt.subplots(8,8, figsize=(8,8))
for i in range(8):
    for j in range(8):
        axs[i,j].imshow(activations[0,:,:,i*8+j])
        axs[i,j].axis('off')
plt.show()

image = cv2.imread('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/bonsai.jpg')
image =image.astype("float32") / 255.0
img=cv2.resize(image, (224, 224))


model = keras.models.load_model('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/VGG19_model.h5')

layer_outputs = [layer.output for layer in model.layers if 'block1_conv1' in layer.name]
activation_model = Model(inputs=model.input, outputs=layer_outputs)
activations = activation_model.predict(np.expand_dims(img, axis=0))

import matplotlib.pyplot as plt

fig, axs = plt.subplots(8,8, figsize=(8,8))
for i in range(8):
    for j in range(8):
        axs[i,j].imshow(activations[0,:,:,i*8+j])
        axs[i,j].axis('off')
plt.show()

image = cv2.imread('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/kangaroo.jpg')
image =image.astype("float32") / 255.0
img=cv2.resize(image, (224, 224))


model = keras.models.load_model('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/VGG19_model.h5')

layer_outputs = [layer.output for layer in model.layers if 'block1_conv1' in layer.name]
activation_model = Model(inputs=model.input, outputs=layer_outputs)
activations = activation_model.predict(np.expand_dims(img, axis=0))

import matplotlib.pyplot as plt

fig, axs = plt.subplots(8,8, figsize=(8,8))
for i in range(8):
    for j in range(8):
        axs[i,j].imshow(activations[0,:,:,i*8+j])
        axs[i,j].axis('off')
plt.show()

image = cv2.imread('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/laptop.jpg')
image =image.astype("float32") / 255.0
img=cv2.resize(image, (224, 224))


model = keras.models.load_model('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/VGG19_model.h5')

layer_outputs = [layer.output for layer in model.layers if 'block1_conv1' in layer.name]
activation_model = Model(inputs=model.input, outputs=layer_outputs)
activations = activation_model.predict(np.expand_dims(img, axis=0))

import matplotlib.pyplot as plt

fig, axs = plt.subplots(8,8, figsize=(8,8))
for i in range(8):
    for j in range(8):
        axs[i,j].imshow(activations[0,:,:,i*8+j])
        axs[i,j].axis('off')
plt.show()

image = cv2.imread('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/watch.jpg')
image =image.astype("float32") / 255.0
img=cv2.resize(image, (224, 224))


model = keras.models.load_model('/content/drive/MyDrive/Deep_learning/Group_9_Assignment5/Architecture_data/VGG19_model.h5')

layer_outputs = [layer.output for layer in model.layers if 'block1_conv1' in layer.name]
activation_model = Model(inputs=model.input, outputs=layer_outputs)
activations = activation_model.predict(np.expand_dims(img, axis=0))

import matplotlib.pyplot as plt

fig, axs = plt.subplots(8,8, figsize=(8,8))
for i in range(8):
    for j in range(8):
        axs[i,j].imshow(activations[0,:,:,i*8+j])
        axs[i,j].axis('off')
plt.show()